# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434

# Model settings
# 임베딩 모델 (nomic-embed-text 권장)
EMBEDDING_MODEL=nomic-embed-text

# LLM 모델 (선택)
# 경량: qwen2.5:3b, gemma3:4b
# 중간: qwen2.5:7b, llama3.1:8b
# 고성능: qwen2.5:14b, llama3.1:70b
CHAT_MODEL=qwen2.5:3b

# RAG settings
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K=3
